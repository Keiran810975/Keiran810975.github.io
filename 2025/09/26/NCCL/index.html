<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/huh.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/huh.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.21.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"always","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":true,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="世界上最好的正面沙鹰使用者">
<meta property="og:type" content="article">
<meta property="og:title" content="NCCL">
<meta property="og:url" content="http://example.com/2025/09/26/NCCL/index.html">
<meta property="og:site_name" content="PIGMilk的博客">
<meta property="og:description" content="世界上最好的正面沙鹰使用者">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2025-09-26T08:18:56.000Z">
<meta property="article:modified_time" content="2025-09-27T08:31:27.459Z">
<meta property="article:author" content="PIGMilk">
<meta property="article:tag" content="集合通信库">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/2025/09/26/NCCL/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2025/09/26/NCCL/","path":"2025/09/26/NCCL/","title":"NCCL"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>NCCL | PIGMilk的博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">PIGMilk的博客</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">PIGMIlk's Blog</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-主页"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a></li><li class="menu-item menu-item-个人简介"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>个人简介</a></li><li class="menu-item menu-item-分类"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>分类</a></li><li class="menu-item menu-item-归档"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E8%BF%B0"><span class="nav-number">1.</span> <span class="nav-text">概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89-NCCL%EF%BC%9F"><span class="nav-number">1.1.</span> <span class="nav-text">为什么要有 NCCL？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%AF%E6%8C%81%E7%9A%84%E9%80%9A%E4%BF%A1%E5%8E%9F%E8%AF%AD"><span class="nav-number">1.2.</span> <span class="nav-text">支持的通信原语</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E4%BA%9B"><span class="nav-number">1.3.</span> <span class="nav-text">一些</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#PCIe%E5%92%8CNVLink"><span class="nav-number">1.3.1.</span> <span class="nav-text">PCIe和NVLink</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%85%B3%E7%B3%BB"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">关系</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NVSwitch"><span class="nav-number">1.3.2.</span> <span class="nav-text">NVSwitch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#InfiniBand-IB"><span class="nav-number">1.3.3.</span> <span class="nav-text">InfiniBand (IB)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RDMA-Remote-Direct-Memory-Access"><span class="nav-number">1.3.4.</span> <span class="nav-text">RDMA (Remote Direct Memory Access)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#GPUDirect-RDMA"><span class="nav-number">1.3.5.</span> <span class="nav-text">GPUDirect RDMA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9C%A8%E5%88%86%E5%B8%83%E5%BC%8F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">1.3.6.</span> <span class="nav-text">在分布式深度学习中的作用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IB%EF%BC%8CPCIe%EF%BC%8CNVLink%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="nav-number">1.3.7.</span> <span class="nav-text">IB，PCIe，NVLink的关系</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%9A%E4%BF%A1%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%AE%97%E6%B3%95"><span class="nav-number">1.4.</span> <span class="nav-text">通信模式与算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NCCL%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="nav-number">1.5.</span> <span class="nav-text">NCCL实现原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="nav-number">1.5.1.</span> <span class="nav-text">1. 核心思想</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%85%B8%E5%9E%8B%E5%8E%9F%E8%AF%AD%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95"><span class="nav-number">1.5.2.</span> <span class="nav-text">2. 典型原语的实现方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%B9-Broadcast"><span class="nav-number">1.5.2.1.</span> <span class="nav-text">🔹 Broadcast</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%B9-Allreduce"><span class="nav-number">1.5.2.2.</span> <span class="nav-text">🔹 Allreduce</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%B9-Reduce-Allgather-Reduce-Scatter"><span class="nav-number">1.5.2.3.</span> <span class="nav-text">🔹 Reduce &#x2F; Allgather &#x2F; Reduce-Scatter</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%F0%9F%94%B9-Barrier%EF%BC%88%E9%9A%90%E5%BC%8F%E5%AE%9E%E7%8E%B0%EF%BC%89"><span class="nav-number">1.5.2.4.</span> <span class="nav-text">🔹 Barrier（隐式实现）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%8B%93%E6%89%91%E6%84%9F%E7%9F%A5%E4%BC%98%E5%8C%96"><span class="nav-number">1.5.3.</span> <span class="nav-text">3. 拓扑感知优化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-%E5%BC%82%E6%AD%A5%E4%B8%8E%E6%89%A7%E8%A1%8C%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.5.4.</span> <span class="nav-text">4. 异步与执行模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82%E4%B8%8A%E7%9A%84%E5%85%B3%E9%94%AE%E7%82%B9"><span class="nav-number">1.5.5.</span> <span class="nav-text">5. 实现细节上的关键点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-%E5%92%8C-MPI-%E7%9A%84%E5%8C%BA%E5%88%AB%EF%BC%88%E5%AE%9E%E7%8E%B0%E5%B1%82%E9%9D%A2%EF%BC%89"><span class="nav-number">1.5.6.</span> <span class="nav-text">6. 和 MPI 的区别（实现层面）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NCCL-%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">1.6.</span> <span class="nav-text">NCCL 的使用</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="PIGMilk"
      src="/images/turtle.png">
  <p class="site-author-name" itemprop="name">PIGMilk</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">32</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Keiran810975" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Keiran810975" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:23676866@qq.com" title="E-Mail → mailto:23676866@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/yourname" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;yourname" rel="noopener me" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/yourname" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;yourname" rel="noopener me" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.facebook.com/yourname" title="FB Page → https:&#x2F;&#x2F;www.facebook.com&#x2F;yourname" rel="noopener me" target="_blank"><i class="fab fa-facebook fa-fw"></i>FB Page</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/yourname" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;yourname" rel="noopener me" target="_blank"><i class="fab fa-stack-overflow fa-fw"></i>StackOverflow</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://youtube.com/yourname" title="YouTube → https:&#x2F;&#x2F;youtube.com&#x2F;yourname" rel="noopener me" target="_blank"><i class="fab fa-youtube fa-fw"></i>YouTube</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://instagram.com/yourname" title="Instagram → https:&#x2F;&#x2F;instagram.com&#x2F;yourname" rel="noopener me" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
      <span class="links-of-author-item">
        <a href="skype:yourname?call|chat" title="Skype → skype:yourname?call|chat" rel="noopener me" target="_blank"><i class="fab fa-skype fa-fw"></i>Skype</a>
      </span>
  </div>
  <div class="cc-license animated" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></a>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/09/26/NCCL/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/turtle.png">
      <meta itemprop="name" content="PIGMilk">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="PIGMilk的博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="NCCL | PIGMilk的博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          NCCL
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-09-26 16:18:56" itemprop="dateCreated datePublished" datetime="2025-09-26T16:18:56+08:00">2025-09-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2025-09-27 16:31:27" itemprop="dateModified" datetime="2025-09-27T16:31:27+08:00">2025-09-27</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>世界上最好的正面沙鹰使用者</p>
<span id="more"></span>

<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p><strong>NCCL</strong>（NVIDIA Collective Communication Library）是 <strong>NVIDIA 提供的高性能集合通信库</strong>，专门针对 <strong>多 GPU</strong> 和 <strong>多节点 GPU 集群</strong>的通信优化。</p>
<ul>
<li>全称：<em>NVIDIA Collective Communication Library</em></li>
<li>用途：为深度学习框架（PyTorch、TensorFlow、MXNet 等）提供高效的 <strong>allreduce、broadcast、allgather、reduce、reduce_scatter</strong> 等集合通信。</li>
<li>底层优化：利用 GPU 的高速互联（PCIe、NVLink、NVSwitch、InfiniBand、RoCE 等），避免不必要的 CPU 参与。</li>
</ul>
<hr>
<h2 id="为什么要有-NCCL？"><a href="#为什么要有-NCCL？" class="headerlink" title="为什么要有 NCCL？"></a>为什么要有 NCCL？</h2><p>在深度学习训练里：</p>
<ul>
<li><strong>数据并行</strong>：每个 GPU 处理一部分数据，得到一份梯度。</li>
<li><strong>需要同步</strong>：所有 GPU 必须把梯度汇总（allreduce），保证参数一致。</li>
</ul>
<p>传统做法：</p>
<ul>
<li>用 <strong>MPI</strong> 也能做集合通信，但 MPI 设计时主要面向 CPU → GPU 上效率不佳（需要 GPU&lt;-&gt;CPU 拷贝）。</li>
</ul>
<p>NCCL 的改进：</p>
<ul>
<li><strong>GPU aware</strong>：直接在 GPU 内存上操作，不需要拷贝到 host。</li>
<li><strong>拓扑感知</strong>：自动发现 GPU 之间的连接拓扑（PCIe 拓扑、NVLink、IB&#x2F;RDMA），选择最优通信路径。</li>
<li><strong>带宽最优</strong>：默认使用 <strong>环 (ring) allreduce</strong>，对大消息带宽利用率接近 100%。</li>
</ul>
<hr>
<h2 id="支持的通信原语"><a href="#支持的通信原语" class="headerlink" title="支持的通信原语"></a>支持的通信原语</h2><p>NCCL 提供的主要操作和 MPI 的集合通信类似：</p>
<ul>
<li><code>ncclBroadcast</code></li>
<li><code>ncclReduce</code></li>
<li><code>ncclAllReduce</code></li>
<li><code>ncclAllGather</code></li>
<li><code>ncclReduceScatter</code></li>
<li>（没有提供点对点 send&#x2F;recv，因为专注于集体操作）</li>
</ul>
<p>这些接口是异步的，通常配合 CUDA stream 调用。</p>
<hr>
<h2 id="一些"><a href="#一些" class="headerlink" title="一些"></a>一些</h2><h3 id="PCIe和NVLink"><a href="#PCIe和NVLink" class="headerlink" title="PCIe和NVLink"></a>PCIe和NVLink</h3><ul>
<li>NVlink：NVIDIA 自研的高速互联总线（不是行业通用标准），主要用于 GPU ↔ GPU、GPU ↔ CPU 之间的通信。解决 PCIe 带宽不够的问题。</li>
<li>PCIe：PCIe (Peripheral Component Interconnect Express) 是 通用标准，所有外设（GPU、SSD、网卡等）都通过它挂载到 CPU 主板上。现在基本上所有的 GPU、网卡、SSD、FPGA 等外设，都是通过 PCIe 插槽接到 CPU 主板上的。</li>
<li></li>
</ul>
<h4 id="关系"><a href="#关系" class="headerlink" title="关系"></a>关系</h4><ul>
<li><p><strong>层次关系</strong></p>
<ul>
<li><p>PCIe：通用互联标准（CPU ↔ 外设的“高速公路”）。</p>
</li>
<li><p>NVLink：专门优化 GPU ↔ GPU &#x2F; GPU ↔ CPU 的通信（更像 GPU 之间的“高速专用通道”）。</p>
</li>
</ul>
</li>
<li><p><strong>互补关系</strong></p>
<ul>
<li><p>GPU 最初都要通过 PCIe 插槽连接到主板，所以 PCIe 是“基础连接”。</p>
</li>
<li><p>如果 GPU 支持 NVLink，并且主板上有 NVLink Bridge &#x2F; NVSwitch，那么 GPU 之间会优先用 NVLink 通信，不再依赖 PCIe。</p>
</li>
</ul>
</li>
<li><p><strong>在 NCCL &#x2F; 深度学习里的作用</strong></p>
<ul>
<li>单机多卡训练：</li>
<li>如果有 NVLink，NCCL 会利用 NVLink 做 allreduce，速度远超 PCIe。</li>
<li>如果没有 NVLink，只能走 PCIe。</li>
</ul>
</li>
<li><p>多机多卡训练：<br>GPU ↔ GPU 跨节点通信，仍然通过 PCIe ↔ 网卡 (InfiniBand&#x2F;RoCE) ↔ PCIe ↔ GPU 完成。</p>
</li>
</ul>
<p>但在单机内部，NVLink 负责 GPU ↔ GPU，PCIe 负责 GPU ↔ NIC。</p>
<h3 id="NVSwitch"><a href="#NVSwitch" class="headerlink" title="NVSwitch"></a>NVSwitch</h3><p>🔹 <strong>NVSwitch 是什么？</strong></p>
<ul>
<li><p><strong>NVSwitch</strong> 是 NVIDIA 推出的 <strong>高性能 GPU 互联交换芯片</strong>。</p>
</li>
<li><p>它的作用：</p>
<ul>
<li>把多条 <strong>NVLink</strong> 连接起来，像一个“交换机”一样，把一堆 GPU 组织成 <strong>全互连（all-to-all）网络</strong>。</li>
</ul>
</li>
<li><p>可以理解为：</p>
<ul>
<li><strong>NVLink</strong> &#x3D; 点对点的专用高速通道</li>
<li><strong>NVSwitch</strong> &#x3D; 一个中心交换机，让所有 GPU 互相都能高速通信</li>
</ul>
</li>
</ul>
<p>🔹 <strong>为什么需要 NVSwitch？</strong></p>
<ul>
<li><p>NVLink 本质是 <strong>点对点连接</strong>。</p>
<ul>
<li>例子：V100 有 6 条 NVLink → 最多直连 6 个 GPU</li>
<li>超过 6 个 GPU 时，不可能让每对 GPU 都直接连 NVLink。</li>
<li>会出现 <strong>非全互联</strong>：有的 GPU 需要“转发”才能通信 → 带宽下降。</li>
</ul>
</li>
<li><p>NVSwitch 的出现，解决了这个问题：</p>
<ul>
<li>所有 GPU 都通过 NVLink 连接到 NVSwitch</li>
<li>NVSwitch 内部做数据转发，相当于 GPU 之间有一个高速交换网络</li>
<li>从 GPU 的角度看，<strong>任何两块 GPU 的带宽都是一致的</strong></li>
</ul>
</li>
</ul>
<p>🔹 <strong>带宽</strong></p>
<ul>
<li>**NVSwitch (V100时代)**：每个 GPU 连接 6 条 NVLink 到 NVSwitch，每条 25 GB&#x2F;s 双向，总带宽 <strong>300 GB&#x2F;s&#x2F;GPU</strong>。</li>
<li>**NVSwitch (A100时代)**：带宽翻倍，每 GPU <strong>600 GB&#x2F;s</strong>。</li>
<li>**NVSwitch (H100时代)**：每 GPU 可达 <strong>900 GB&#x2F;s</strong>。</li>
</ul>
<p>这种带宽远超 PCIe（32–64 GB&#x2F;s），让 <strong>8卡&#x2F;16卡&#x2F;32卡 服务器</strong> 内部 GPU 之间通信几乎无瓶颈。</p>
<p>🔹 <strong>NVSwitch 的应用场景</strong></p>
<ul>
<li><p><strong>DGX 系列服务器</strong>（比如 DGX-2、DGX A100、DGX H100）</p>
<ul>
<li>内部 GPU 通过 NVSwitch 全互连。</li>
<li>例如 DGX-2：16 个 V100 GPU，全互联，任意两 GPU 通信带宽 &#x3D; 300 GB&#x2F;s。</li>
</ul>
</li>
<li><p><strong>HGX 平台</strong>（各大云厂商 GPU 服务器的基础设计）</p>
<ul>
<li>8&#x2F;16&#x2F;32&#x2F;64 GPU 节点内部都用 NVSwitch 打通。</li>
</ul>
</li>
<li><p><strong>NCCL</strong></p>
<ul>
<li>在有 NVSwitch 的节点上，NCCL 可以直接利用 NVSwitch 进行集合通信，allreduce 几乎线性扩展。</li>
</ul>
</li>
</ul>
<p>🔹 <strong>类比</strong></p>
<ul>
<li><p><strong>PCIe</strong>：城市里的主干道，大家都能走，但带宽有限。</p>
</li>
<li><p><strong>NVLink</strong>：点对点的专用高速路，快，但直连数量有限。</p>
</li>
<li><p><strong>NVSwitch</strong>：一个超大高速交换中心，所有 GPU 都连到这里 → <strong>全互联网络</strong>。</p>
</li>
<li><p><strong>NVSwitch</strong>：把 NVLink 扩展成多 GPU 全互联交换网络。</p>
</li>
<li><p>在 <strong>单机多 GPU（8&#x2F;16&#x2F;32卡）训练</strong>中，NVSwitch 是核心支撑，让 GPU 之间的通信带宽远高于 PCIe。</p>
</li>
</ul>
<h3 id="InfiniBand-IB"><a href="#InfiniBand-IB" class="headerlink" title="InfiniBand (IB)"></a>InfiniBand (IB)</h3><p> 🔹 是什么？</p>
<ul>
<li><p>InfiniBand 是一种 <strong>高性能网络互连标准</strong>，广泛用于 <strong>超级计算机和数据中心</strong>。</p>
</li>
<li><p>目标：比以太网&#x2F;PCIe 提供 <strong>更高带宽、更低延迟</strong> 的节点间通信。</p>
</li>
<li><p>典型参数（现代 HDR&#x2F;NDR IB 网卡）：</p>
<ul>
<li>带宽：200 Gbps (HDR)，400 Gbps (NDR)</li>
<li>延迟：亚微秒级（&lt;1µs），远低于传统 TCP&#x2F;IP 网络</li>
</ul>
</li>
</ul>
<p> 🔹 特点</p>
<ol>
<li><strong>支持 RDMA</strong>：允许一台机器直接读写另一台机器的内存。</li>
<li><strong>硬件加速</strong>：网络层很多操作在网卡（HCA, Host Channel Adapter）里完成，CPU 开销小。</li>
<li><strong>可扩展</strong>：常用于超算集群的数千节点互连。</li>
</ol>
<h3 id="RDMA-Remote-Direct-Memory-Access"><a href="#RDMA-Remote-Direct-Memory-Access" class="headerlink" title="RDMA (Remote Direct Memory Access)"></a>RDMA (Remote Direct Memory Access)</h3><p>🔹 是什么？</p>
<ul>
<li>RDMA &#x3D; 远程直接内存访问</li>
<li>允许一台机器的网卡 <strong>直接读&#x2F;写另一台机器的内存</strong>，不需要对方 CPU 参与。</li>
</ul>
<p>🔹 优势</p>
<ul>
<li><strong>低延迟</strong>：绕过内核，不用走 TCP&#x2F;IP 协议栈。</li>
<li><strong>低开销</strong>：不需要目标 CPU 参与，大幅减轻 CPU 负担。</li>
<li><strong>高带宽</strong>：结合 InfiniBand，几乎能打满链路带宽。</li>
</ul>
<p>🔹 使用场景</p>
<ul>
<li>分布式深度学习（梯度同步）</li>
<li>分布式数据库（远程读写数据块）</li>
<li>HPC 科学计算（MPI over RDMA）</li>
</ul>
<h3 id="GPUDirect-RDMA"><a href="#GPUDirect-RDMA" class="headerlink" title="GPUDirect RDMA"></a>GPUDirect RDMA</h3><ul>
<li>GPUDirect RDMA &#x3D; <strong>GPU 直接远程内存访问</strong></li>
<li>NVIDIA 提供的一项技术，允许 <strong>GPU 内存直接通过 InfiniBand 网卡访问远程节点的 GPU 内存</strong>。</li>
</ul>
<p>传统方式（没有 GPUDirect）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPU → (PCIe) → CPU 内存 → (NIC) → 网络 → (NIC) → CPU 内存 → (PCIe) → GPU</span><br></pre></td></tr></table></figure>

<p>数据要经过 <strong>GPU-CPU-网卡</strong> 的多次拷贝，延迟和带宽都受限。</p>
<p>有了 GPUDirect RDMA：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GPU → (PCIe) → NIC → 网络 → NIC → (PCIe) → GPU</span><br></pre></td></tr></table></figure>

<ul>
<li>直接在 GPU 内存和远端 GPU 内存之间传输数据</li>
<li>跳过 CPU 内存，避免多余拷贝</li>
<li>延迟更低，带宽更高</li>
</ul>
<p>🔹 条件</p>
<ul>
<li>需要 GPU + 支持 GPUDirect 的 InfiniBand NIC（Mellanox 网卡）</li>
<li>驱动和 CUDA 支持</li>
</ul>
<h3 id="在分布式深度学习中的作用"><a href="#在分布式深度学习中的作用" class="headerlink" title="在分布式深度学习中的作用"></a>在分布式深度学习中的作用</h3><ul>
<li><p><strong>单机多卡</strong>：用 NVLink &#x2F; NVSwitch</p>
</li>
<li><p><strong>跨节点多卡</strong>：通过 InfiniBand + RDMA + GPUDirect RDMA</p>
</li>
<li><p><strong>NCCL</strong>：会检测环境，如果有 IB + GPUDirect RDMA，就直接走 GPU-GPU 跨节点通信（延迟和带宽都最佳）</p>
</li>
<li><p><strong>InfiniBand</strong>：高速网络互连，硬件层面提供大带宽+低延迟</p>
</li>
<li><p><strong>RDMA</strong>：允许远程机器直接读写内存，减少 CPU 参与</p>
</li>
<li><p><strong>GPUDirect RDMA</strong>：把 RDMA 扩展到 GPU 内存，GPU 之间可以直接跨节点通信</p>
</li>
<li><p><strong>深度学习训练</strong>：单机靠 NVLink&#x2F;NVSwitch，多机靠 InfiniBand + GPUDirect RDMA</p>
</li>
</ul>
<h3 id="IB，PCIe，NVLink的关系"><a href="#IB，PCIe，NVLink的关系" class="headerlink" title="IB，PCIe，NVLink的关系"></a>IB，PCIe，NVLink的关系</h3><ul>
<li>层次关系<ul>
<li>PCIe：基础互联，所有设备都挂在 PCIe 上</li>
<li>NVLink：在单机内部，给 GPU 之间提供更快的通信（比 PCIe 快一个数量级）</li>
<li>InfiniBand：在多机之间，提供高速网络连接（配合 RDMA&#x2F;GPUDirect）</li>
</ul>
</li>
<li>通信路径<ul>
<li>单机内 GPU ↔ GPU<ul>
<li>如果有 NVLink&#x2F;NVSwitch → 首选 NVLink 通信</li>
<li>没有 NVLink → 走 PCIe</li>
</ul>
</li>
<li>跨机 GPU ↔ GPU<ul>
<li>GPU → (PCIe) → NIC (IB网卡) → IB 网络 → NIC → (PCIe) → GPU</li>
<li>如果启用 GPUDirect RDMA → GPU 内存可以直接被远端 GPU 访问</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="通信模式与算法"><a href="#通信模式与算法" class="headerlink" title="通信模式与算法"></a>通信模式与算法</h2><p>NCCL 内部实现里，最典型的是 <strong>环 Allreduce</strong>：</p>
<ul>
<li>把数据分成 <code>p</code> 块（p &#x3D; GPU 数量）。</li>
<li><strong>reduce-scatter 阶段</strong>：每个 GPU 和邻居交换分块，并做局部归约。</li>
<li><strong>allgather 阶段</strong>：再把完整结果广播回来。</li>
<li>总通信量是 <em><em>2</em>(p-1)&#x2F;p * 数据大小</em>*，几乎达到理论带宽上限。</li>
</ul>
<p>此外，NCCL 也支持：</p>
<ul>
<li><strong>树形算法</strong>（小消息、低延迟场景）。</li>
<li><strong>拓扑感知算法</strong>（在 NVSwitch &#x2F; 多机环境下自动选择）。</li>
</ul>
<hr>
<h2 id="NCCL实现原理"><a href="#NCCL实现原理" class="headerlink" title="NCCL实现原理"></a>NCCL实现原理</h2><h3 id="1-核心思想"><a href="#1-核心思想" class="headerlink" title="1. 核心思想"></a>1. 核心思想</h3><p>NCCL 的目标：<strong>高带宽 + 低延迟的 GPU 集体通信</strong>。</p>
<p>它的实现原理主要依赖以下几点：</p>
<ol>
<li><p><strong>GPU 内存直通（GPUDirect RDMA &#x2F; GPUDirect P2P）</strong></p>
<ul>
<li>避免 GPU ↔ CPU ↔ GPU 的多次拷贝。</li>
<li>GPU 可以直接通过 NVLink&#x2F;PCIe&#x2F;InfiniBand 交换数据。</li>
</ul>
</li>
<li><p><strong>拓扑感知（Topology-aware scheduling）</strong></p>
<ul>
<li>NCCL 启动时会自动探测节点内外 GPU 的连接拓扑（PCIe 层级、NVLink、NVSwitch、IB）。</li>
<li>根据拓扑决定最佳通信模式（环、树、分层）。</li>
</ul>
</li>
<li><p><strong>算法选择（Ring &#x2F; Tree &#x2F; Hierarchical）</strong></p>
<ul>
<li>大消息 → <strong>环算法</strong>，带宽最优。</li>
<li>小消息 → <strong>树算法</strong>，延迟更低。</li>
<li>多机多卡 → <strong>分层算法</strong>，先在节点内通信，再跨节点通信。</li>
</ul>
</li>
<li><p><strong>异步 + CUDA Stream 执行</strong></p>
<ul>
<li>通信操作以 CUDA kernel 形式在 GPU 上执行，用户可通过流（stream）与计算并行。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="2-典型原语的实现方法"><a href="#2-典型原语的实现方法" class="headerlink" title="2. 典型原语的实现方法"></a>2. 典型原语的实现方法</h3><h4 id="🔹-Broadcast"><a href="#🔹-Broadcast" class="headerlink" title="🔹 Broadcast"></a>🔹 Broadcast</h4><ul>
<li><strong>树型实现</strong>（小消息）：root GPU 把数据发给直接相连的 GPU，层层传下去。</li>
<li><strong>环实现</strong>（大消息）：把数据切成块，按环方向传输，每个 GPU 负责传给下一个。</li>
</ul>
<hr>
<h4 id="🔹-Allreduce"><a href="#🔹-Allreduce" class="headerlink" title="🔹 Allreduce"></a>🔹 Allreduce</h4><p>NCCL 的招牌操作，大多数深度学习框架的梯度同步都靠它。</p>
<p><strong>环 Allreduce 的两阶段</strong>：</p>
<ol>
<li><p><strong>Reduce-Scatter</strong>（归约 + 分发）</p>
<ul>
<li>将数据切成 <em>p</em> 块（p &#x3D; GPU 数）。</li>
<li>每轮：每个 GPU 把自己的一块发给邻居，同时接收邻居的块并做归约。</li>
<li>经过 p-1 轮，每个 GPU 持有一块全局归约后的结果。</li>
</ul>
</li>
<li><p><strong>Allgather</strong>（汇集）</p>
<ul>
<li>再经过 p-1 轮交换，把完整结果分发给所有 GPU。</li>
</ul>
</li>
</ol>
<p><strong>通信量</strong>：</p>
<ul>
<li>总传输量 &#x3D; <code>2 * (p-1)/p * 数据大小</code></li>
<li>接近带宽理论最优（比 naive 全收全发少很多）。</li>
</ul>
<p>NCCL 还会在大消息时做 <strong>流水线分块</strong>，边收边算边发。</p>
<hr>
<h4 id="🔹-Reduce-Allgather-Reduce-Scatter"><a href="#🔹-Reduce-Allgather-Reduce-Scatter" class="headerlink" title="🔹 Reduce &#x2F; Allgather &#x2F; Reduce-Scatter"></a>🔹 Reduce &#x2F; Allgather &#x2F; Reduce-Scatter</h4><ul>
<li>都是上面 <strong>环 &#x2F; 树</strong> 的变体。</li>
<li>Reduce-Scatter + Allgather 可以组合成 Allreduce。</li>
</ul>
<hr>
<h4 id="🔹-Barrier（隐式实现）"><a href="#🔹-Barrier（隐式实现）" class="headerlink" title="🔹 Barrier（隐式实现）"></a>🔹 Barrier（隐式实现）</h4><ul>
<li>NCCL 没有单独的 Barrier，而是通过 <strong>空消息广播</strong> 或 <strong>allreduce(1, SUM)</strong> 来实现同步。</li>
</ul>
<hr>
<h3 id="3-拓扑感知优化"><a href="#3-拓扑感知优化" class="headerlink" title="3. 拓扑感知优化"></a>3. 拓扑感知优化</h3><p>NCCL 的一大亮点是 <strong>自动发现并利用拓扑</strong>：</p>
<ul>
<li>在单机多 GPU：优先走 <strong>NVLink</strong>（带宽高、延迟低）；如果 GPU 不直接连 NVLink，就走 PCIe。</li>
<li>在多机环境：通过 <strong>GPUDirect RDMA</strong> + InfiniBand&#x2F;RDMA 直连，不绕过 CPU 内存。</li>
<li>在有 NVSwitch 的服务器（如 DGX-2、DGX-A100）：构建 <strong>全带宽无阻塞环</strong>，多环并行。</li>
</ul>
<p><strong>层次化算法（Hierarchical collectives）</strong>：</p>
<ul>
<li><strong>第一层</strong>：节点内（利用 NVLink &#x2F; NVSwitch 做 allreduce）。</li>
<li><strong>第二层</strong>：节点间（利用 InfiniBand 做 allreduce）。</li>
<li><strong>最后</strong>：再节点内广播。</li>
</ul>
<p>这样能同时发挥 <strong>节点内高速互联</strong> 和 <strong>跨节点带宽</strong> 的优势。</p>
<hr>
<h3 id="4-异步与执行模型"><a href="#4-异步与执行模型" class="headerlink" title="4. 异步与执行模型"></a>4. 异步与执行模型</h3><ul>
<li><p>NCCL 的 API 是异步的，操作被插入到 <strong>CUDA Stream</strong> 中：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ncclAllReduce(sendbuff, recvbuff, N, ncclFloat, ncclSum, comm, stream);</span><br></pre></td></tr></table></figure></li>
<li><p>NCCL 会启动 CUDA kernel 在 GPU 上发起通信请求，</p>
<ul>
<li>GPU 直接驱动 DMA 传输（RDMA）。</li>
<li>CPU 只负责初始化和调度，不需要参与数据搬运。</li>
</ul>
</li>
<li><p>这样通信可以和计算 overlap（比如梯度计算和 allreduce 并行）。</p>
</li>
</ul>
<hr>
<h3 id="5-实现细节上的关键点"><a href="#5-实现细节上的关键点" class="headerlink" title="5. 实现细节上的关键点"></a>5. 实现细节上的关键点</h3><ol>
<li><p><strong>协议选择</strong></p>
<ul>
<li>小消息 → 低延迟协议（LL、LL128，减少启动开销）。</li>
<li>大消息 → 简单协议（Simple，最大化带宽）。</li>
</ul>
</li>
<li><p><strong>多环并行</strong></p>
<ul>
<li>在大规模 GPU 集群中，NCCL 会建立多条环并行传输，提高链路利用率。</li>
</ul>
</li>
<li><p><strong>错误处理与容错</strong></p>
<ul>
<li>NCCL 早期对容错支持有限，但在分布式训练（尤其是深度学习）中会通过上层框架（Horovod、PyTorch DDP）做重试或恢复。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="6-和-MPI-的区别（实现层面）"><a href="#6-和-MPI-的区别（实现层面）" class="headerlink" title="6. 和 MPI 的区别（实现层面）"></a>6. 和 MPI 的区别（实现层面）</h3><table>
<thead>
<tr>
<th>对比点</th>
<th>MPI</th>
<th>NCCL</th>
</tr>
</thead>
<tbody><tr>
<td>通用性</td>
<td>CPU&#x2F;GPU 都支持</td>
<td>只支持 GPU</td>
</tr>
<tr>
<td>通信模式</td>
<td>点对点 + 集合</td>
<td>只提供集合通信</td>
</tr>
<tr>
<td>GPU 支持</td>
<td>GPU-aware 需要特别编译</td>
<td>原生 GPU 优化</td>
</tr>
<tr>
<td>调度</td>
<td>通用算法（树、环、递归加倍）</td>
<td>针对 GPU 拓扑定制，自动选择</td>
</tr>
<tr>
<td>性能</td>
<td>在 GPU 上通常低于 NCCL</td>
<td>GPU 场景下几乎最佳</td>
</tr>
</tbody></table>
<hr>
<h2 id="NCCL-的使用"><a href="#NCCL-的使用" class="headerlink" title="NCCL 的使用"></a>NCCL 的使用</h2><p>……</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E9%9B%86%E5%90%88%E9%80%9A%E4%BF%A1%E5%BA%93/" rel="tag"># 集合通信库</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/09/26/ccl_2/" rel="prev" title="CCL_2">
                  <i class="fa fa-angle-left"></i> CCL_2
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/09/27/megatron/" rel="next" title="Megatron">
                  Megatron <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">PIGMilk</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  




  <script src="https://cdnjs.cloudflare.com/ajax/libs/quicklink/2.3.0/quicklink.umd.js" integrity="sha256-yvJQOINiH9fWemHn0vCA5lsHWJaHs6/ZmO+1Ft04SvM=" crossorigin="anonymous"></script>
  <script class="next-config" data-name="quicklink" type="application/json">{"enable":true,"home":true,"archive":true,"delay":true,"timeout":3000,"priority":true,"url":"http://example.com/2025/09/26/NCCL/"}</script>
  <script src="/js/third-party/quicklink.js"></script>

</body>
</html>
